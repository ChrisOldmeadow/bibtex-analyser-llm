{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibtex Analyzer - Interactive Demo\n",
    "\n",
    "This notebook demonstrates the interactive features of the Bibtex Analyzer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if not already installed\n",
    "!pip install bibtexparser openai plotly matplotlib numpy ipykernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ OpenAI API key found\n"
     ]
    }
   ],
   "source": [
    "# Dependencies\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import random\n",
    "from typing import Optional\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Dict, Any\n",
    "import openai  # Add this line for OpenAI integration\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Verify OpenAI API key is set\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    print(\"‚ö†Ô∏è Warning: OPENAI_API_KEY not found in environment variables\")\n",
    "    print(\"Please create a .env file with your OpenAI API key like this:\")\n",
    "    print(\"OPENAI_API_KEY=your-api-key-here\")\n",
    "else:\n",
    "    print(\"‚úÖ OpenAI API key found\")\n",
    "\n",
    "# Import bibtex analyzer components\n",
    "from bibtex_analyzer import process_bibtex_file, TagGenerator\n",
    "from bibtex_analyzer.visualization import create_tag_network\n",
    "\n",
    "# Updated word cloud function\n",
    "def create_wordcloud_visualization(\n",
    "    data: pd.DataFrame,\n",
    "    tag_column: str = \"tags\",\n",
    "    width: int = 1000,\n",
    "    height: int = 800,\n",
    "    max_words: int = 100,\n",
    "    background_color: str = \"white\",\n",
    "    colormap: str = \"viridis\",\n",
    "    **kwargs\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Create a word cloud visualization using the wordcloud package.\n",
    "    \n",
    "    Args:\n",
    "        data: DataFrame containing the data\n",
    "        tag_column: Name of the column containing tags\n",
    "        width: Width of the output figure\n",
    "        height: Height of the output figure\n",
    "        max_words: Maximum number of words to include\n",
    "        background_color: Background color of the word cloud\n",
    "        colormap: Matplotlib colormap to use\n",
    "        **kwargs: Additional arguments passed to WordCloud\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Flatten all tags\n",
    "        all_tags = []\n",
    "        for tag_list in data[tag_column]:\n",
    "            tags = [tag.strip().lower() for tag in str(tag_list).split(\",\")]\n",
    "            all_tags.extend(tags)\n",
    "        \n",
    "        # Count tag frequencies\n",
    "        tag_counts = {}\n",
    "        for tag in all_tags:\n",
    "            tag = tag.strip()\n",
    "            if tag and tag.lower() != 'nan':  # Skip empty and 'nan' tags\n",
    "                tag_counts[tag] = tag_counts.get(tag, 0) + 1\n",
    "        \n",
    "        if not tag_counts:\n",
    "            print(\"‚ö†Ô∏è No valid tags found for word cloud\")\n",
    "            return\n",
    "            \n",
    "        # Create word cloud\n",
    "        wordcloud = WordCloud(\n",
    "            width=width,\n",
    "            height=height,\n",
    "            background_color=background_color,\n",
    "            max_words=max_words,\n",
    "            colormap=colormap,\n",
    "            **kwargs\n",
    "        ).generate_from_frequencies(tag_counts)\n",
    "        \n",
    "        # Display the generated image\n",
    "        plt.figure(figsize=(width/100, height/100), dpi=100)\n",
    "        plt.imshow(wordcloud, interpolation='bilinear')\n",
    "        plt.axis(\"off\")\n",
    "        plt.tight_layout(pad=0)\n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error generating word cloud: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4baffb5b87cd485191843765cb33e47b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>Bibtex Analyzer</h3>'), HBox(children=(Label(value='Upload BibTeX file:'), File‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create widgets for user input\n",
    "file_upload = widgets.FileUpload(description=\"Upload .bib file\", accept='.bib', multiple=False)\n",
    "generate_btn = widgets.Button(description=\"Generate Analysis\")\n",
    "output = widgets.Output()\n",
    "\n",
    "# Display the widgets\n",
    "display(widgets.VBox([\n",
    "    widgets.HTML(\"<h3>Bibtex Analyzer</h3>\"),\n",
    "    widgets.HBox([widgets.Label(\"Upload BibTeX file:\"), file_upload]),\n",
    "    generate_btn,\n",
    "    output\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_generate_clicked(b):\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        \n",
    "        if not file_upload.value:\n",
    "            print(\"Please upload a .bib file first\")\n",
    "            return\n",
    "            \n",
    "        try:\n",
    "            # Get the uploaded file content\n",
    "            file_info = file_upload.value[0]  # Get the first file\n",
    "            content = file_info['content']\n",
    "            \n",
    "            # Save to a temporary file\n",
    "            temp_file = \"temp_upload.bib\"\n",
    "            with open(temp_file, 'wb') as f:\n",
    "                f.write(content)\n",
    "            \n",
    "            try:\n",
    "                # Process the BibTeX file\n",
    "                print(\"üìö Processing BibTeX file...\")\n",
    "                entries = process_bibtex_file(temp_file)\n",
    "                \n",
    "                # Filter out entries without abstracts\n",
    "                entries_with_abstracts = [e for e in entries if e.get('abstract')]\n",
    "                if len(entries_with_abstracts) < len(entries):\n",
    "                    print(f\"‚ÑπÔ∏è {len(entries) - len(entries_with_abstracts)} entries skipped (no abstract)\")\n",
    "                \n",
    "                if not entries_with_abstracts:\n",
    "                    print(\"‚ùå No entries with abstracts found. Please upload a .bib file with entries containing abstracts.\")\n",
    "                    return\n",
    "                \n",
    "                print(f\"‚úÖ Found {len(entries_with_abstracts)} entries with abstracts\")\n",
    "                \n",
    "                # Take a random sample of 10 entries with abstracts for tag generation\n",
    "                import random\n",
    "                random.seed(42)  # For reproducibility\n",
    "                sample_for_tags = min(10, len(entries_with_abstracts))\n",
    "                if sample_for_tags < 3:  # Need at least 3 entries for meaningful tags\n",
    "                    print(\"‚ùå Need at least 3 entries with abstracts to generate meaningful tags\")\n",
    "                    return\n",
    "                \n",
    "                tag_entries = random.sample(entries_with_abstracts, sample_for_tags)\n",
    "                \n",
    "                # Take a random sample of 10 entries with abstracts for tagging\n",
    "                sample_to_tag = min(10, len(entries_with_abstracts))\n",
    "                entries_to_tag = random.sample(entries_with_abstracts, sample_to_tag)\n",
    "                \n",
    "                print(f\"\\nüîç Analyzing {sample_for_tags} entries to generate tags...\")\n",
    "                tagger = TagGenerator()\n",
    "                \n",
    "                try:\n",
    "                    # Generate tags from the sample - ensure we're passing the full entry dicts\n",
    "                    print(\"Generating tags from abstracts...\")\n",
    "                    tags = tagger.generate_tags_for_abstracts(tag_entries)  # Pass the full entry dicts\n",
    "                    \n",
    "                    if not tags:\n",
    "                        print(\"‚ö†Ô∏è No tags were generated. The abstracts might be too short or not in English.\")\n",
    "                        return\n",
    "                        \n",
    "                    print(f\"üéØ Generated {len(tags)} unique tags\")\n",
    "                    print(\"üè∑Ô∏è  Tags:\", \", \".join(tags))\n",
    "                    \n",
    "                    # Tag the sample entries\n",
    "                    print(f\"\\nüè∑Ô∏è  Tagging {sample_to_tag} random entries...\\n\")\n",
    "                    all_tagged_entries = []\n",
    "                    for i, entry in enumerate(entries_to_tag, 1):\n",
    "                        entry_tags = tagger.assign_tags_to_abstracts([entry], list(tags))\n",
    "                        print(f\"üìÑ Entry {i}:\")\n",
    "                        print(f\"   Title: {entry.get('title', 'No title')}\")\n",
    "                        print(f\"   Year: {entry.get('year', 'N/A')}\")\n",
    "                        print(f\"   Tags: {entry_tags[0].get('tags', 'No tags')}\\n\")\n",
    "                        all_tagged_entries.append(entry_tags[0])\n",
    "                    \n",
    "                    # Generate word cloud if we have tags\n",
    "                    # Generate word cloud if we have tags\n",
    "                    # Generate word cloud if we have tags\n",
    "                    if tags and all_tagged_entries:\n",
    "                        print(\"\\nüåê Generating word cloud of tags...\")\n",
    "                        try:\n",
    "                            # Create a DataFrame for visualization\n",
    "                            df = pd.DataFrame(all_tagged_entries)\n",
    "                            if not df.empty and 'tags' in df.columns and not df['tags'].isna().all():\n",
    "                                create_wordcloud_visualization(\n",
    "                                    df,\n",
    "                                    width=1200,\n",
    "                                    height=800,\n",
    "                                    max_words=100,\n",
    "                                    background_color='white',\n",
    "                                    colormap='viridis',\n",
    "                                    prefer_horizontal=0.9,\n",
    "                                    scale=2,\n",
    "                                    min_font_size=10,\n",
    "                                    max_font_size=120\n",
    "                                )\n",
    "                            else:\n",
    "                                print(\"‚ö†Ô∏è Not enough data to generate word cloud\")\n",
    "                        except Exception as e:\n",
    "                            print(f\"‚ö†Ô∏è Could not generate word cloud: {str(e)}\")\n",
    "                                        \n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Error during tagging: {str(e)}\")\n",
    "                    import traceback\n",
    "                    traceback.print_exc()\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå An error occurred: {str(e)}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "                \n",
    "            finally:\n",
    "                # Clean up\n",
    "                if os.path.exists(temp_file):\n",
    "                    os.remove(temp_file)\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error handling file upload: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "# Connect button click to handler\n",
    "generate_btn.on_click(on_generate_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
